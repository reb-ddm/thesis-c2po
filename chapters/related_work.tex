\chapter{Related Work}


\section{Congruence Closure}

The congruence cloure algorithm is widely used in the field of formal verifcation,
when reasoning about the equivalence of terms. It was introduced in the early 1980s
in different variations. \textcite{cc-tarjan} described a congruence closure algorithm
where each element is directly mapped to its representative, thus not requiring the
use of a union-find data structure.
The methods of \textcite{cc-nelson,cc-shostak} are based on a union-find data structure~\cite{uf-tarjan}, as
is done in this master's thesis. They doesn't directly use a finite automata to represent
the congruence closure, but define the procedure directly on graphs,
allowing to define the congruence closure of terms that contain arbitrary uninterpreted function symbols
of any arity.
Our quantitative congruence closure is similar, but restricted to a single uniterpreted function $*$
and extended to handle simple arithmetic operations.
This quantitative congruence closure for 2-Pointer Logic was introduced by \textcite{2pointer}.

The congruence closure algorithm can also be viewed as a rewrite system,
for rewriting canonical normal forms of terms by replacing subterms with their representatives,
as in \cite{cc-kapur,abstract-cc}.
There exists an extension with integer offsets for this approach, as described by \textcite{cc-offsets}.
This is done in a similar way to our approach, but it doesn't use union-find and it considers a
binary function $\cdot$, where the offset is added to the second argument.

Join algorithms for congruence closure are described by \textcite{join},
where the join operation is defined over the congruence closure described
as a rewrite system.
This join was adapted here to the desciption of the congruence closure that uses a quantitative finite automata.
An alternative join is also introduced here, that does not take into account the information of the
quantitative automata, but only the partition of the union-find data structure.
It is less precise, but in practical examples it finds mostly the same results as the more precise join.


\section{Pointer Analysis}


There are numerous pointer analyses for C programs that are used in static analysis tools.
As C is widely used in crucial code bases, such as operating systems, device drivers, and embedded systems,
it is important to beable to prove correctness properties about the pointers used in these programs.
For a comprehensive overview of pointer analyses, see \textcite{pointeranalysis}.

The recent work on pointer analysis can be roughly divided into three categories:
fast flow- and context-insensitive analyses, non-relational context-sensitive analyses, and very precise shape analyses.

\textcite{Andersen,Steensgaard} proposed very fast, but not so precise, analyses for very large programs.
These analyses are flow-insensitive and context-insensitive, which means that they remember a set of possible
addresses for each pointer, and they do not distinguish between different offsets inside a memory block.
The analysis also does not take into account a specific program point or call context, but it summarizes the
value of the variable in one set of addresses for the whole program.
This is a very efficient way to analyze programs, but it is not precise enough to prove intricate properties about prorgams.

The same idea can be applied in a context- and flow-sensitive way, by providing a set of possible addresses for each pointer at each program point and call context.
This is used in multiple practical C analyzers, such as \textsf{Mopsa}~\cite{mopsa}, \textsf{Frama-C}~\cite{framac,BÃ¼hler2024} and \textsf{Goblint}~\cite{goblint}.
This non-relational analysis is more precise than the flow-insensitive analysis, but when the sets are not singletons,
it can no longer infer relational properties about the pointers.
Our relatioinal analysis is therefore a good complement to these analyses, as it can infer additional
properties about the pointers, i.e.mustequalities and disequalities between terms made up of pointers, dereferencing and pointer arithmetic.
In this master's thesis, the non-relational pointer analysis by \textcite{goblint} is used in combination
with the newly implemented relational analysis in order to augment the precision of the analysis.

Shape analyses are a third category of pointer analyses, which are very precise and can infer complex properties about pointers and about the shape and content of data structures.
Some examples are~\cite{shapeanalysis,kreiker,separationlogic,rivalpapers,predator,Lemerre2024}.
These analyses are very precise, but also very expensive in terms of time and memory consumption.
The analysis of this master's thesis is a compromise between the precision of shape analysis and
the efficiency of less precises analysis, by only considering relations between pairs of pointers.

\section{Relational analysis/weakly relational}

The idea of restricting the number of variables in relational analysis has been precedently used
for other domains than pointers, such as numerical domains and strings.
